 %!TEX TS-program = xelatex
%!TEX encoding = UTF-8 Unicode

\def \papersize {a4paper}

\documentclass[12pt,\papersize]{extarticle}
% extarticle is like article but can handle 8pt, 9pt, 10pt, 11pt, 12pt, 14pt, 17pt, and 20pt text

\def \ititle {Is This a Counterexample to Bratman on Shared Intention?}
\def \isubtitle {}
\def \iauthor {Stephen A.\ Butterfill}
\def \iemail{s.butterfill@warwick.ac.uk}
%\date{}

\input{$HOME/Documents/submissions/preamble_steve_paper3}
%\author{}
%\date{}



%\setromanfont[Mapping=tex-text]{Sabon LT Std} 

\begin{document}

\setlength\footnotesep{1em}

\bibliographystyle{$HOME/Documents/submissions/mynewapa} %apalike

\maketitle
%\tableofcontents
\title{}

\begin{abstract}
\noindent
***

\end{abstract}

\section{Shared Intention}
Why, if at all, is a notion of shared intention needed? 
This question is standardly answered by appeal to contrast cases \citep[compare][p.\ 150]{Bratman:2009lv}.
Thus \citet{gilbert_walking_1990} contrasts our intentionally walking together with two people who happen to be walking side by side. 
And \citet{Searle:1990em} contrasts park visitors who  simultaneously run to a central shelter in performing a dance with park visitors who likewise run to the central shelter but only because of an impending storm. 
These and other contrast cases invite the question, 
How does our intentionally acting together differ from our merely acting in parallel? 
The first contrast case, Gilbert's, shows that the difference can’t be just  a matter of coordination because people who are merely happen to be walking side by side each other also need to coordinate their actions in order to avoid colliding.  
Note also that in both cases each individual's walking is intentional, so our intentionally walking together cannot be a matter only of our each intentionally walking.
The second contrast case, Searle's, shows that the difference can’t just be that the resulting actions have a common effect because merely parallel actions can have common effects too.%
\footnote{
This use of contrast cases resembles \citet{Pears:1971fk}: he uses contrast cases to argue that whether something is an ordinary, individual action depends on its antecedents. 
} 
Perhaps, then, a notion of shared intention is needed to distinguish the two cases.  
Perhaps it is our acting on a shared intention that we walk together which distinguishes us from two strangers who happen to be walking side by side.%
\footnote{
Many philosophers agree that a notion of shared intention is useful for understanding acting together. 
Compare \citet[p.\ 5]{Gilbert:2006wr}: `I take a collective action to involve a collective intention.'  See also  
	\citet[p.\ 381]{Carpenter:2009wq}, 
	\citet[p.\ 369]{Call:2009fk}, 
	\citet{Kutz:2000si}, 
	\citet[p.\ 117]{rakoczy_pretend_2006} and 
	\citet{Tollefsen:2005vh}.
	}
	

But what could shared intention be?
In an influential series of papers,\footnote{ 
See \citet{Bratman:1992mi,Bratman:1993je,Bratman:1999fr,Bratman:2009lv}.
For influences beyond philosophy, see e.g.\ \citet{Tomasello:2005wx} and \citet{Knoblich:2008hy}. 
}
Bratman claims that the following are collectively sufficient\footnotemark \ conditions for you and I to have a shared intention that we J:
%
\footnotetext{
In \citet{Bratman:1992mi}, the following were offered as jointly sufficient \textit{and individually necessary} conditions; the retreat to sufficient conditions occurs in \citet[][pp.\ 143-4]{Bratman:1999fr} where he notes that `for all that I have said, shared intention might be multiply realizable.'
} 
%
\begin{quote}
\label{quote:bratman_account}
`1. (a) I intend that we J and (b) you intend that we J
 
`2. I intend that we J in accordance with and because of la, lb, and meshing subplans of la and lb; you intend that we J in accordance with and because of la, lb, and meshing subplans of la and lb
 
`3. 1 and 2 are common knowledge between us' \citep[][p.\ View 4]{Bratman:1993je}
\end{quote}
%
Care is needed in specifying the contents of the intentions concerning our J-ing in these clauses. 
As mentioned above, an appeal to shared intention is supposed to  characterise systematically a difference between two agents who intentionally J together (e.g.\ walk  together) and two agents who also  J together but do not do so intentionally (e.g.\ they happen to be walking side by side). 
So we must avoid tacitly appealing to this distinction by  restricting possible values of J to those which involve our intentionally doing something together. 
Rather the above  conditions, (1)--(3), must be sufficient for shared intention even for some values of J which are `neutral with respect to shared intentionality'.%
\footnote{
 \citet[p.\ 147]{Bratman:1999fr}.
 This refines Bratman's earlier view that some admissable values of J are cooperatively neutral 
 	where an  act-type is \emph{cooperatively neutral} just if `joint performance of an act of that type may be cooperative, but it need not be' \citep[p.\ 330]{Bratman:1992mi}. 
}

A consequence is that, in the right situations, one of us can rationally intend that we J, and can intend this unilaterally, that is without depending on anyone else intending that we J. 
Suppose you know that I am going to Chicago via a certain route at a particular time, 
and that I will do this regardless of what you do.
Suppose also that you can rationally intend that you go to Chicago in the same manner.
Then you can rationally intend that we go to Chicago together, 
	and you can intend this irrespective of whether I have any corresponding intention---providing, of course, that in so intending you are conceiving of our going to Chicago together in a way that is neutral with respect to shared intentionality.
What follows depends on the premise that this is indeed possible.%
\footnote{ 
\citet{Bratman:1999fr}  defends this claim at length. 
Note also that this claim must be true if Bratman's account of shared intention is to provide an informative way of distinguishing between the contrast cases mentioned at the start.
}


In this paper we give a counterexample to Bratman's  claim that the above conditions, (1)--(3), are collectively sufficient conditions for shared intention. 
We shall also suggest a revision which would enable the counterexample to be avoided.
Apart from improving our understanding of what shared intention is, 
this will also bear on the kinds of planning that are involved in acting together.

Before going further we must distinguish two versions of the claim that (1)--(3) are collectively sufficient for shared intention.
The \emph{weak claim} is that there is some J such that these conditions are sufficient for you and I to intend that we J.
The \emph{strong claim} is that for any J, these conditions are sufficient for you and I to intend that we J.
One of Bratman's aims is to show that it is possible to give an account of shared intention using concepts that `are available within the theory of individual planning agency' \citep[p.\ 163]{Bratman:2009lv}.  
Achieving this aim would require the strong claim, and it is to the strong claim that our counterexample is directed. 




\section{Unshared Intentions}
Before we can introduce the counterexample we need to introduce what we shall call `unshared intentions'.
We have an \emph{unshared intention} that we <J$_1$, J$_2$> where J$_1$$\neq$J$_2$ just if:
%
\begin{quote}
\label{df:unshared_intention}
1. (a) I intend that we J$_1$ and (b) you intend that we J$_2$
 
2. I intend that we J$_1$ in accordance with and because of la, lb, and meshing subplans of la and lb; you intend that we J$_2$ in accordance with and because of la, lb, and meshing subplans of la and lb
 
3. 1 and 2 are common knowledge between us.
\end{quote}
In defining unshared intention we have used conditions exactly like Bratman's sufficient conditions for shared intention except that Bratman's conditions have J$_1$$=$J$_2$.
At this point it might be natural for readers to suppose that agents could not have unshared intentions,
or at least that they could not do so without irrationality.
In this section we describe a possible situation in which two agents  have an unshared intention without irrationality, deception or even ignorance.


Let us first introduce the activity we shall focus on.
Ayesha and Benji  are playing a simple video game which involves moving a cross around a two-dimensional space littered with barriers.
Ayesha can only accelerate the cross backwards or forwards,
while Benji can only accelerate it left or right. 
The cross moves around and interacts with the barriers in ways both players can predict.
The players are given tasks independently. 
These tasks always involve making the cross hit a target within two minutes of starting. 
A player succeeds when the cross hits her target, regardless of what happens to the cross afterwards.  
(It may go on to hit another target.)
In this case, 
	Ayesha's task is to make the cross hit the red square
	while
	Benji's task is make the cross hit the blue circle. 
In general it is possible that either or both will succeed, or that they will both fail.
Each movement carries a small cost to the player who moves, so that Ayesha and Benji each attempt to minimize how much he or she moves the cross consistently with completing his or her task.
Ayesha and Benji are each neutral on whether the other succeeds or fails.
They are not opponents and do not seek to undermine each other's efforts, but each is entirely concerned  with his or her own task.
All of this is common knowledge for Ayesha and Benji.
They both know who has which task, what constraints they face and what their motives are.

Consider the possibility of one player intending, unilaterally, that the two players do something.
Suppose that one of the players---Ayesha, say---can knowledgeably predict that if she performs a certain sequence actions, <a$_1$, a$_2$, ...\ a$_n$>, then Benji will simultaneously perform certain other actions, <b$_1$, b$_2$, ...\ b$_n$>,
 and the upshot will be that the cross hits the red square.
Were this to happen, we could say, truthfully, that Ayesha and Benji made the cross hit the red square.
Suppose, further, that Ayesha can intend to perform those actions <a$_1$, a$_2$, ...\ a$_n$>.
Then Ayesha can intend, unilaterally, that they, Ayesha and Benji, make the cross hit the red square.

Unshared intentions require a kind of symmetry.
Let us suppose that the above sequences of actions,
	Ayesha's <a$_1$, a$_2$, ...\ a$_n$>  and 
	Benji's <b$_1$, b$_2$, ...\ b$_n$>,
will also result in the cross hitting the blue circle. 
(Since the cross has momentum, we can suppose that it will hit both the red square and the blue circle at some time after these actions are performed.)
Then by the reasoning just offered, Benji could intend that they, Ayesha and Benji make the cross hit the blue circle.
So Ayesha and Benji could meet the first condition, (1), for having an unshared intention.

What about the second condition, (2)?
Suppose that Ayesha knows two further things.
First, that Benji intends that they, Ayesha and Benji, make the cross hit the blue circle.
Second, that in acting on his intention Benji will perform actions <b$_1$, b$_2$, ...\ b$_n$>.
Then Ayesha can intend that they, Ayesha and Benji, make the cross hit the red square in accordance with and because of her intention that they make the cross hit the red square and in accordance with and because of Benji's intention that they make the cross hit the blue circle.

This is not quite enough to meet the second condition, (2), because there is also a requirement about meshing subplans. 
To make sense of this requirement we need to generalise Bratman's definition of meshing:
\begin{quote}
`our individual subplans concerning our J-ing \emph{mesh} just in case there is some way we could J that would not violate either of our subplans but would, rather, involve the successful execution of those subplans' \citep[p.\ 106]{Bratman:1993je}.
\end{quote}
A natural generalisation is this:
\begin{quote}
our individual subplans concerning our <J$_1$, J$_2$>-ing \emph{mesh} just in case there is some way we could <J$_1$, J$_2$> that would not violate either of our subplans but would, rather, involve the successful execution of those subplans. 
\end{quote}
%
To illustrate, 
there would be a failure to mesh if, in intending that they make the cross hit the red square,  Ayesha's plans had included pushing Benji out of the way and seizing his controls. 
But in the case we have been describing there is no such failure to mesh.
Each agent's subplans involve manipulating his or her own controls,
and the successes each seeks in doing this depends on the other successfully carrying out their subplans.
So Ayesha can rationally intend that they, Ayesha and Benji, make the cross hit the red square in accordance with and because of their intentions and meshing subplans of them.
And Benji likewise for making the cross hit the blue circle.

The only outstanding requirement for Ayesha and Benji to have an unshared intention is that their various intentions are common knowledge. 
Assuming common knowledge is possible where agents have a shared intention, it is likewise possible in this case of unshared intention.
So Ayesha and Benji can have an unshared intention that they <J$_1$, J$_2$> where J$_1$ is Ayesha and Benji's making the cross hit the red square and J$_2$ is their making the cross hit the blue circle.

So far we have shown that it is possible for two agents to have an unshared intention without irrationality, deception or ignorance.
Of course unshared intentions may be rare. 
But what matters for our counterexample is just that they are possible. 



\section{Pure unshared intentions}
An unshared intention is \emph{pure} if having that unshared intention does not involve having any shared intention. 
It may initially appear obvious that all unshared intentions are pure. 
This is less obvious than it seems, however.
Since Bratman provides only sufficient conditions for shared intention, his account doesn't tell us that the unshared intention is not a shared intention.
For all Bratman says, the conditions defining unshared intention might also be collectively sufficient conditions for shared intention. 
And while we might be tempted to assume that for two agents to intentionally J together they must at least each have intentions concerning J, 
this assumption might reasonably be rejected by those who, like Bratman, reject the Simple View according to which when an individual intentionally J-s she has an intention concerning her J-ing \citep{Bratman:1984jr}.
So the purity of an unshared intention cannot be assumed without argument.

How could we establish the purity of a particular unshared intention? 
For reasons that will become clear later, we need to show that  Ayesha and Benji's unshared intention that they <J$_1$, J$_2$>  is pure.

This question might initially appear frivolous but it is not straightforward to answer.
Since Bratman provides only sufficient conditions for shared intention, his account doesn't tell us that the unshared intention is not a shared intention.
And while we might be tempted to assume that for two agents to intentionally J together they must at least each have intentions concerning J, 
this assumption might reasonably be rejected by those who, like Bratman, reject the Simple View according to which when an individual intentionally J-s she has an intention concerning her J-ing \citep{Bratman:1984jr}.




\section{The Counterexample}
*Need a beefier activity, something more than cooperatively neutral.

In the situation just described,
Ayesha and Benji are playing a game and have different tasks.
Thanks to special features of the game environment, they both succeed by acting on an unshared intention.
Now compare two further players, Yasmin and Zak, who are playing the same game. 
Their situations, knowledge states, intentions and actions are as similar as possible to Ayesha's and Benji's except for one detail.
Just by chance they have been assigned identical tasks: Yasmin's task is to make the cross hit the red square and Zak's task is the same.
So where Ayesha and Benji have an unshared intention that they <J$_1$, J$_2$>,
Yasmin and Zak meet Bratman's conditions (1)--(3) for having a shared intention that they J$_1$.  
But these intentions, the unshared intention and the Bratman intention (as we might call the structure of intention and knowledge), result in them performing same actions (Yasmin does what Ayesha does, Zak what Benji does) in the same way. 

We shall argue that although Yasmin and Zak meet Bratman's conditions (1)--(3) for having a shared intention that they J$_1$, they do not have any such shared intention.
This, then, is our counterexample.
Of course it is probably not yet obvious that Yasmin and Zak do not have a shared intention.
To see that they do not we need to introduce one more case.

We started this paper by explaining the need for a notion of shared intention by appeal to contrast cases. 
An account of shared intention should enable us to  distinguish systematically between two types of case in which we J together, one where we intentionally J together and the other where  our J-ing together involves  merely parallel actions.
As noted, Gilbert's example of walking together shows that merely parallel actions can be mutually responsive, as when two strangers walking side by side avoid collision thanks to meshing subplans.



*Yasmin and Zak: it's like we've tied the Gilbert's walking strangers' ankles together, so that they can only succeed together.





***


Our argument is:
\begin{enumerate}[label=\roman*]
\item Yasmin and Zak have a shared intention that they J$_1$ only if Ayesha and Benji have a shared intention in virtue of having the 
 unshared intention that they <J$_1$, J$_2$>.
\item Ayesha and Benji's unshared intention that they <J$_1$, J$_2$> is a not shared intention.
\end{enumerate}
%
Therefore:
%
\begin{enumerate}[resume,label=\roman*]
\item Yasmin and Zak do not have a shared intention that they J$_1$.
\end{enumerate}
%
In the rest of this section we defend the two premises, starting with the second, (ii).

Could Ayesha and Benji's unshared intention that they <J$_1$, J$_2$> be a  shared intention?
This question might initially appear frivolous but it is not straightforward to answer.
Since Bratman provides only sufficient conditions for shared intention, his account doesn't tell us that the unshared intention is not a shared intention.
And while we might be tempted to assume that for two agents to intentionally J together they must at least each have intentions concerning J, 
this assumption might reasonably be rejected by those who, like Bratman, reject the Simple View according to which when an individual intentionally J-s she has an intention concerning her J-ing \citep{Bratman:1984jr}.

In defence of the second premise, (ii), consider that shared intentions are suppose to play a certain functional role.
Among other things, they are supposed to coordinate 







\section{Prior counterexamples}
***Must mention that Tollefsen and Gold \& Sugden counterexamples fail.


\section{The Counterexample}
Suppose that Aravinda runs the trains and Gerhard  the busses.
Let us stipulate that the extent to which the two services, train and bus, are coordinated is to be measured by the total time passengers spend waiting between a bus and a train.
So changes to the timetables would result in better coordination just if the changes would total waiting time.
To illustrate, improving coordination might involve having trains arrive at a station shortly before, rather than shortly after, busses depart from there.
Now Aravinda and Gerhard each intend that they, Aravinda and Gerhard, coordinate the trains with the busses to the greatest extent possible given other constraints; and they intend to do this by way of these intentions and meshing subplans of them, and this is common knowledge between them. 
Aravinda and Gerhard thus meet Bratman's sufficient conditions for them to have a shared intention.
Acting on this intention, 
every January Aravinda updates the train timetables and sends Gerhard the changes.
Likewise, Gerhard  updates the bus timetables every June and sends Aravinda the changes.
In this way  each is responsive to the other's intentions and subplans of these. 
Indeed, each may even try to predict changes in the other's subplans and modify their own accordingly.  
But from each individual's point of view, the other's plans are  merely a constraint.

***

So whether Gerhard succeeds relative to his intention depends on both his own and Aravinda's plans; and likewise for Aravinda.
%This is why each intends that they optimally coordinate the services in accordance with meshing subplans.
This is why each is responsive to the other's plans. 
Indeed, each may even try to predict changes in the other's plans and modify their own accordingly.  
But from each individual's point of view, the other's plans are  merely a constraint.
This approach to planning suffers from two defects.
First, it is unlikely to be optimal in the sense of resulting, eventually, in a combination of plans such that no other combination of plans would have been better for at least one service and no worse for either service.
Second, it is unlikely to be efficient in the sense of allowing Gerhard and Aravinda to arrive at an optimal combination of plans for the two services, trains and buses, with the fewest iterations.
How could they do better?
One possibility may be to have a single plan covering busses and trains---perhaps, for example, Aravinda could buy Gerhard's franchise. 
%But suppose that this is not possible, and that there are limits on how much information Aravinda and Gerhard can share. 
Now there is a single goal to which Aravinda and Gerhard's activities are both directed.
But suppose that this is not possible, and that they are unable to integrate their planning more tightly---practical constraints or regulation prevents them from opening up their planning to each other.
Can they still do better than treat each other's plans as a constraint?
Possibly.
Each plans the whole bus--train operation. 

New contrast case: Aravinda and Gerhard planning the whole thing vs. merely responding to each other's plans.
Meet Bratman's sufficient conditions for shared intention in both cases.
(Specifically, in both cases they act on a shared intention that they coordinate the trains with the busses to the greatest extent possible given other constraints.)
But intuitively is a case of coordinating the trains with the busses together whereas the other case involves Aravinda and Gerhard merely doing this in parallel.
So shared intention is insufficient to fully explain the contrast cases.

I'm also inclined to think it is not necessary for solving the contrast cases (distributive goals ...\ collective goals).
The contrast cases do not provide a firm anchor for theorising about shared intention.



\bibliography{$HOME/endnote/phd_biblio}



\end{document}