 %!TEX TS-program = xelatex
%!TEX encoding = UTF-8 Unicode

\def \papersize {a4paper}

\documentclass[12pt,\papersize]{extarticle}
% extarticle is like article but can handle 8pt, 9pt, 10pt, 11pt, 12pt, 14pt, 17pt, and 20pt text

\def \ititle {Is This a Counterexample to Bratman on Shared Intention?}
\def \isubtitle {}
\def \iauthor {Stephen A.\ Butterfill}
\def \iemail{s.butterfill@warwick.ac.uk}
%\date{}

\input{$HOME/Documents/submissions/preamble_steve_paper3}
%\author{}
%\date{}



%\setromanfont[Mapping=tex-text]{Sabon LT Std} 

\begin{document}

\setlength\footnotesep{1em}

\bibliographystyle{$HOME/Documents/submissions/mynewapa} %apalike

\maketitle
%\tableofcontents
\title{}

\begin{abstract}
\noindent
***

\end{abstract}

\section{Shared Intention}
Why, if at all, is a notion of shared intention needed? 
This question is standardly answered by appeal to contrast cases \citep[compare][p.\ 150]{Bratman:2009lv}.
Thus \citet{gilbert_walking_1990} contrasts our intentionally walking together with two people who happen to be walking side by side. 
And \citet{Searle:1990em} contrasts park visitors who  simultaneously run to a central shelter in performing a dance with park visitors who likewise run to the central shelter but only because of an impending storm. 
These and other contrast cases invite the question, 
How does our intentionally acting together differ from our merely acting in parallel? 
The first contrast case, Gilbert's, shows that the difference can’t be just  a matter of coordination because people who are merely happen to be walking side by side each other also need to coordinate their actions in order to avoid colliding.  
Note also that in both cases each individual's walking is intentional, so our intentionally walking together cannot be a matter only of our each intentionally walking.
The second contrast case, Searle's, shows that the difference can’t just be that the resulting actions have a common effect because merely parallel actions can have common effects too.%
\footnote{
This use of contrast cases resembles \citet{Pears:1971fk}: he uses contrast cases to argue that whether something is an ordinary, individual action depends on its antecedents. 
} 
Perhaps, then, a notion of shared intention is needed to distinguish the two cases.  
Perhaps it is our acting on a shared intention that we walk together which distinguishes us from two strangers who happen to be walking side by side.%
\footnote{
Many philosophers agree that a notion of shared intention is useful for understanding acting together. 
Compare \citet[p.\ 5]{Gilbert:2006wr}: `I take a collective action to involve a collective intention.'  See also  
	\citet[p.\ 381]{Carpenter:2009wq}, 
	\citet[p.\ 369]{Call:2009fk}, 
	\citet{Kutz:2000si}, 
	\citet[p.\ 117]{rakoczy_pretend_2006} and 
	\citet{Tollefsen:2005vh}.
	}
	

But what could shared intention be?
In an influential series of papers,\footnote{ 
See \citet{Bratman:1992mi,Bratman:1993je,Bratman:1999fr,Bratman:2009lv}.
For influences beyond philosophy, see e.g.\ \citet{Tomasello:2005wx} and \citet{Knoblich:2008hy}. 
}
Bratman claims that the following are collectively sufficient\footnotemark \ conditions for you and I to have a shared intention that we J:
%
\footnotetext{
In \citet{Bratman:1992mi}, the following were offered as jointly sufficient \textit{and individually necessary} conditions; the retreat to sufficient conditions occurs in \citet[][pp.\ 143-4]{Bratman:1999fr} where he notes that `for all that I have said, shared intention might be multiply realizable.'
} 
%
\begin{quote}
\label{quote:bratman_account}
`1. (a) I intend that we J and (b) you intend that we J
 
`2. I intend that we J in accordance with and because of la, lb, and meshing subplans of la and lb; you intend that we J in accordance with and because of la, lb, and meshing subplans of la and lb
 
`3. 1 and 2 are common knowledge between us' \citep[][p.\ View 4]{Bratman:1993je}
\end{quote}
%
Care is needed in specifying the contents of the intentions concerning our J-ing in these clauses. 
As mentioned above, an appeal to shared intention is supposed to  characterise systematically a difference between two agents who intentionally J together (e.g.\ walk  together) and two agents who also  J together but do not do so intentionally (e.g.\ they happen to be walking side by side). 
So we must avoid tacitly appealing to this distinction by  restricting possible values of J to those which involve our intentionally doing something together. 
Rather the above  conditions, (1)--(3), must be sufficient for shared intention even for some values of J which are `neutral with respect to shared intentionality'.%
\footnote{
 \citet[p.\ 147]{Bratman:1999fr}.
 This refines Bratman's earlier view that some admissable values of J are cooperatively neutral 
 	where an  act-type is \emph{cooperatively neutral} just if `joint performance of an act of that type may be cooperative, but it need not be' \citep[p.\ 330]{Bratman:1992mi}. 
}

A consequence is that, in the right situations, one of us can rationally intend that we J, and can intend this unilaterally, that is without depending on anyone else intending that we J. 
Suppose you know that I am going to Chicago via a certain route at a particular time, 
and that I will do this regardless of what you do.
Suppose also that you can rationally intend that you go to Chicago in the same manner.
Then you can rationally intend that we go to Chicago together, 
	and you can intend this irrespective of whether I have any corresponding intention---providing, of course, that in so intending you are conceiving of our going to Chicago together in a way that is neutral with respect to shared intentionality.
What follows depends on the premise that this is indeed possible.%
\footnote{ 
\citet{Bratman:1999fr}  defends this claim at length. 
Note also that this claim must be true if Bratman's account of shared intention is to provide an informative way of distinguishing between the contrast cases mentioned at the start.
}


In this paper we give a counterexample to Bratman's  claim that the above conditions, (1)--(3), are collectively sufficient conditions for shared intention. 
We shall also suggest a revision which would enable the counterexample to be avoided.
Apart from improving our understanding of what shared intention is, 
this will also bear on the kinds of planning that are involved in acting together.

Before going further we must distinguish two versions of the claim that (1)--(3) are collectively sufficient for shared intention.
The \emph{weak claim} is that there is some J such that these conditions are sufficient for you and I to intend that we J.
The \emph{strong claim} is that for any J, these conditions are sufficient for you and I to intend that we J.
One of Bratman's aims is to show that it is possible to give an account of shared intention using concepts that `are available within the theory of individual planning agency' \citep[p.\ 163]{Bratman:2009lv}.  
Achieving this aim would require the strong claim, and it is to the strong claim that our counterexample is directed. 




\section{Unshared Intentions}
Before we can introduce the counterexample we need to introduce what we shall call `unshared intentions'.
We have an \emph{unshared intention} that we <J$_1$, J$_2$> where J$_1$$\neq$J$_2$ just if:
%
\begin{quote}
\label{df:unshared_intention}
1. (a) I intend that we J$_1$ and (b) you intend that we J$_2$
 
2. I intend that we J$_1$ in accordance with and because of la, lb, and meshing subplans of la and lb; you intend that we J$_2$ in accordance with and because of la, lb, and meshing subplans of la and lb
 
3. 1 and 2 are common knowledge between us.
\end{quote}
In defining unshared intention we have used conditions exactly like Bratman's sufficient conditions for shared intention except that Bratman's conditions have J$_1$$=$J$_2$.
At this point it might be natural for readers to suppose that agents could not have unshared intentions,
or at least that they could not do so without irrationality.
In this section we describe a possible situation in which two agents  have an unshared intention without irrationality, deception or even ignorance.


Let us first introduce the activity we shall focus on.
Ayesha and Benji  are playing a simple video game which involves moving a cross around a two-dimensional space littered with barriers.
Ayesha can only accelerate the cross backwards or forwards,
while Benji can only accelerate it left or right. 
The cross moves around and interacts with the barriers in ways both players can predict.
The players are given tasks independently. 
These tasks always involve making the cross hit a target within two minutes of starting. 
A player succeeds when the cross hits her target, regardless of what happens to the cross afterwards.  
(It may go on to hit another target.)
In this case, 
	Ayesha's task is to make the cross hit the red square
	while
	Benji's task is make the cross hit the blue circle. 
In general it is possible that either or both will succeed, or that they will both fail.
Each movement carries a small cost to the player who moves, so that Ayesha and Benji each attempt to minimize how much he or she moves the cross consistently with completing his or her task.
Ayesha and Benji are each neutral on whether the other succeeds or fails.
They are not opponents and do not seek to undermine each other's efforts, but each is entirely concerned  with his or her own task.
All of this is common knowledge for Ayesha and Benji.
They both know who has which task, what constraints they face and what their motives are.

Consider the possibility of one player intending, unilaterally, that the two players do something.
Suppose that one of the players---Ayesha, say---can knowledgeably predict that if she performs a certain sequence actions, <a$_1$, a$_2$, ...\ a$_n$>, then Benji will simultaneously perform certain other actions, <b$_1$, b$_2$, ...\ b$_n$>,
 and the upshot will be that the cross hits the red square.
Were this to happen, we could say, truthfully, that Ayesha and Benji made the cross hit the red square.
Suppose, further, that Ayesha can intend to perform those actions <a$_1$, a$_2$, ...\ a$_n$>.
Then Ayesha can intend, unilaterally, that they, Ayesha and Benji, make the cross hit the red square.

Unshared intentions require a kind of symmetry.
Let us suppose that the above sequences of actions,
	Ayesha's <a$_1$, a$_2$, ...\ a$_n$>  and 
	Benji's <b$_1$, b$_2$, ...\ b$_n$>,
will also result in the cross hitting the blue circle. 
(Since the cross has momentum, we can suppose that it will hit both the red square and the blue circle at some time after these actions are performed.)
Then by the reasoning just offered, Benji could intend that they, Ayesha and Benji make the cross hit the blue circle.
So Ayesha and Benji could meet the first condition, (1), for having an unshared intention.

What about the second condition, (2)?
Suppose that Ayesha knows two further things.
First, that Benji intends that they, Ayesha and Benji, make the cross hit the blue circle.
Second, that in acting on his intention Benji will perform actions <b$_1$, b$_2$, ...\ b$_n$>.
Then Ayesha can intend that they, Ayesha and Benji, make the cross hit the red square in accordance with and because of her intention that they make the cross hit the red square and in accordance with and because of Benji's intention that they make the cross hit the blue circle.

This is not quite enough to meet the second condition, (2), because there is also a requirement about meshing subplans. 
To make sense of this requirement we need to generalise Bratman's definition of meshing:
\begin{quote}
`our individual subplans concerning our J-ing \emph{mesh} just in case there is some way we could J that would not violate either of our subplans but would, rather, involve the successful execution of those subplans' \citep[p.\ 106]{Bratman:1993je}.
\end{quote}
A natural generalisation is this:
\begin{quote}
our individual subplans concerning our <J$_1$, J$_2$>-ing \emph{mesh} just in case there is some way we could <J$_1$, J$_2$> that would not violate either of our subplans but would, rather, involve the successful execution of those subplans. 
\end{quote}
%
To illustrate, 
there would be a failure to mesh if, in intending that they make the cross hit the red square,  Ayesha's plans had included pushing Benji out of the way and seizing his controls. 
But in the case we have been describing there is no such failure to mesh.
Each agent's subplans involve manipulating his or her own controls,
and the successes each seeks in doing this depends on the other successfully carrying out their subplans.
So Ayesha can rationally intend that they, Ayesha and Benji, make the cross hit the red square in accordance with and because of their intentions and meshing subplans of them.
And Benji likewise for making the cross hit the blue circle.

The only outstanding requirement for Ayesha and Benji to have an unshared intention is that their various intentions are common knowledge. 
Assuming common knowledge is possible where agents have a shared intention, it is likewise possible in this case of unshared intention.
So Ayesha and Benji can have an unshared intention that they <J$_1$, J$_2$> where J$_1$ is Ayesha and Benji's making the cross hit the red square and J$_2$ is their making the cross hit the blue circle.

So far we have shown that it is possible for two agents to have an unshared intention without irrationality, deception or ignorance.
Of course unshared intentions may be rare. 
But what matters for our counterexample is just that they are possible. 



\section{Pure unshared intentions and imaginary agents [*cut?]}
An unshared intention is \emph{pure} if having that unshared intention does not involve having any shared intention. 
It may initially appear obvious that all unshared intentions are pure. 
This is not obvious, however.
Since Bratman provides only sufficient conditions for shared intention, his account doesn't tell us that the unshared intention is not a shared intention.
For all Bratman says, the conditions defining unshared intention might also be collectively sufficient conditions for shared intention. 
And while we might be tempted to assume that for two agents to intentionally J together they must at least each have intentions concerning J, 
this assumption might reasonably be rejected by those who, like Bratman, reject the Simple View according to which when an individual intentionally J-s she has an intention concerning her J-ing \citep{Bratman:1984jr}.
So the purity of an unshared intention cannot be assumed without argument.

For reasons to be explained later, we need to show that  Ayesha and Benji's unshared intention that they <J$_1$, J$_2$>  is pure.
How could we do this? 
Ayesha sees Benji's actions as constraints on her own, or else as opportunities.
She exploits Benji's intentions for her own ends.
Of course the situation is reciprocal: Benji exploits Ayesha in equal measure.
Each allows himself or herself to be exploited by the other because being exploited enables exploiting.
The sort of shared agency that an account of shared intention is supposed to capture must involve more than this sort of reciprocal exploitation, where each agent sees the other's actions only as constraints or opportunities. 
Intuitively shared agency must somehow involve greater unity.
But how can this intuition support an argument?



We started this paper by explaining the need for a notion of shared intention by appeal to contrast cases (following Bratman). 
It is contrast cases that are supposed give us a pre-theoretical handle on shared intention.
So to show that Ayesha and Benji's unshared intention is pure, we need to construct a contrasting case.

***Lily and Isabel, 
	like many people, 
 	sometimes attribute intentions and other states to imaginary agents, and perform actions on their behalf. 
In some cases this enables them to further their own real-world objectives (as in `Teddy wants to go to the park now').	
Some of these imaginary agents are toys. 
But some are imaginary aggregate agents. 
Sometimes, that is, Lily and Isabel imagine that there is an agent distinct from either of them and such that all its parts are parts of them.
They attribute intentions and other states to this agent, and act on its behalf.






An account of shared intention should enable us to  distinguish systematically between two types of case in which we J together, one where we intentionally J together and the other where  our J-ing together involves  merely parallel actions.
As noted, Gilbert's example of walking together shows that merely parallel actions can be mutually responsive, as when two strangers walking side by side avoid collision thanks to meshing subplans.



\section{The Counterexample}
%*Need a beefier activity, something more than cooperatively neutral.

In the situation just described,
Ayesha and Benji are playing a game and have different tasks.
Thanks to special features of the game environment, they both succeed by acting on an unshared intention.
Now compare two further players, Yasmin and Zak, who are playing the same game. 
Their situations, knowledge states, intentions and actions are as similar as possible to Ayesha's and Benji's except for one detail.
Just by chance they have been assigned identical tasks: Yasmin's task is to make the cross hit the red square and Zak's task is the same.
So where Ayesha and Benji have an unshared intention that they <J$_1$, J$_2$>,
Yasmin and Zak meet Bratman's conditions (1)--(3) for having a shared intention that they J$_1$.  
But these intentions, the unshared intention and the Bratman intention (as we might label the structure of intention and knowledge while leaving open whether it constitutes a shared intention), result in them performing same actions in the same way.
That is, Yasmin reasons about Zak much as Ayesha reasons about Benji and Yasmin and does what Ayesha does, and likewise for Zak and Benji. 

We shall argue that Yasmin and Zak do not have a shared intention that they J$_1$ despite meeting meet Bratman's conditions (1)--(3).
This is probably not yet obvious, however.
Let us first attempt to provide some intuitive support for this claim.
Return to Ayesha and Benji for a moment.
Ayesha sees Benji's actions as constraints to work around and opportunities to exploit.
She exploits Benji's intentions for her own ends.
Of course the situation is reciprocal: Benji exploits Ayesha in equal measure.
Each allows himself or herself to be exploited by the other because being exploited enables exploiting.
The sort of shared agency that an account of shared intention is supposed to capture must involve more than this sort of reciprocal exploitation, where each agent merely exploits the other's intentions. 
But Yasmin and Zak are engaged in just the same sort of reciprocal exploitation as Ayesha and Benji.
The only difference is that, quite by chance, Yasmin's task and Zak's task are the same.
So, intuitively, Yasmin and Zak, like Ayesha and Benji, belong in the same category as two people who happen to be walking side by side and not in the category exemplified by two people intentionally walking together.

Assuming for a moment that this is right,
what might explain the difference between Yasmin and Zak on the one hand and cases like Gilbert's two people intentionally walking together on the other hand?
To answer this question in the spirit of Bratman's planning-theoretic approach, we need to step back and think about planning generally.

Imagine observing Ayesha and Benji as they play the game. 
Suppose you decide to make a plan of action for one or both of them.
In doing this you could either adopt one player's perspective or you could adopt a fictional shared perspective.
Adopting one player's perspective, Ayesha's say, 
	you think about what she might do to achieve her task,
	predict how this will influence Benji's actions,
	and then feed  these predictions back into the question of what Ayesha might do.
From this perspective, Benji's actions are constraints to work around and opportunities to exploit.
Alternatively you might adopt a fictional shared perspective, 
	 mentally replacing Ayesha and Benji with a single, imaginary aggregate agent who has to perform both tasks alone.
	 In this case, you think about what combination of actions would best achieve both tasks and then, right at the end, you assign these actions to Ayesha and Benji.
From this perspective, it is as if there is a single mind behind the plan.

Note that the number of agents involved does not dictate which perspective we can take.
Just as we could take a fictional shared perspective where two or more agents are involved, 
so also we could take a fictional split perspective on the actions of  a single agent, and even of ourselves.
The newly elected  politician with a young family and working partner might see herself almost as if she were two people engaged in different projects while forced to shared a single body. 

Shared perspective of a fictional aggregate agent.
Can be a matter of negotiation what the fictional aggregate agent's values, preferences and intentions are.

Perhaps the reason why Yasmin and Zak fail to have a shared intention (if they do---this has not yet been argued) is that each plans entirely from her own perspective. 
Maybe shared intention sometimes requires that agents be disposed to plan at least some of their actions from a shared perspective.

Now consider a third (and final) pair of players, Lily and Isabel.
Lily and Isabel each take the appropriate shared perspective, as if imagining a fictional aggregate agent who had been assigned their two tasks, 
and they plan accordingly.
And this is common knowledge.
What matters is not what they do, however.
It is that the J which they intend is characterised in terms of planning from a shared perspective.
What they intend when they intend that they J does not leave it open whether they will adopt a shared perspective in planning their J-ing.
J is neutral with respect to shared intention but it is not neutral with respect to the requirement that each agent individually adopt a shared perspective when planning how to J.
***HERE



Imagine two tasks need to be completed; perhaps you need to buy some shoes and get a haircut. 
Which actions you perform in attempting the first task constrains what actions you can perform in attempting the second task, and conversely.
For instance, if you shop for the shoes in one store, you won't have enough money left for the best hairdressers.
There are two ways to approach planning these tasks.
One approach involves treating the two tasks as separate.
Perhaps you first think of a plan that is optimal for buying shoes.
Then, taking this plan as a constraint, you attempt to plan the haircut.
But as it happens you discover that the options for the haircut are unsatisfactory.
So you revise the shoe-buying plan and try again to plan the haircut.
A different approach to planning would be to treat the two tasks as part of a larger, single task.
Perhaps you identify several possible combinations of shoe-buying and haircut-getting actions.
You then ask yourself which combination is best overall and then perform the component actions.




Take a situation like the game Ayesha and Benji are playing but now imagine that you are taking over from both players and intend to perform both tasks. 
One way to plan would involve thinking of two separate tasks.
First you think about the best way to make the cross hit the red square.



%
%The difference separating Ayesha and Benji, on the one hand, from Yasmin and Zak on the other 
%	is unlike the difference separating two strangers who merely happen to be walking side by side from two people intentionally walking together.
%So if Ayesha and Benji's do not intentionally act together, then nor do Yasmin and Zak.


 

***Can get a parallel to the special case discussed here by considering walkers whose legs have been tied together in such a way that they are forced to accommodate each other if they are to get around.  Such people may walk together and meet the Bratman conditions without actually 




We shall argue that although Yasmin and Zak meet Bratman's conditions (1)--(3) for having a shared intention that they J$_1$, they do not have any such shared intention.
This, then, is our counterexample.
Of course it is probably not yet obvious that Yasmin and Zak do not have a shared intention.
To see that they do not we need to introduce one more case.

We started this paper by explaining the need for a notion of shared intention by appeal to contrast cases. 
An account of shared intention should enable us to  distinguish systematically between two types of case in which we J together, one where we intentionally J together and the other where  our J-ing together involves  merely parallel actions.
As noted, Gilbert's example of walking together shows that merely parallel actions can be mutually responsive, as when two strangers walking side by side avoid collision thanks to meshing subplans.



*Yasmin and Zak: it's like we've tied the Gilbert's walking strangers' ankles together, so that they can only succeed together.





***


Our argument is:
\begin{enumerate}[label=\roman*]
\item Yasmin and Zak have a shared intention that they J$_1$ only if Ayesha and Benji have a shared intention in virtue of having the 
 unshared intention that they <J$_1$, J$_2$>.
\item Ayesha and Benji's unshared intention that they <J$_1$, J$_2$> is a not shared intention.
\end{enumerate}
%
Therefore:
%
\begin{enumerate}[resume,label=\roman*]
\item Yasmin and Zak do not have a shared intention that they J$_1$.
\end{enumerate}
%
In the rest of this section we defend the two premises, starting with the second, (ii).

Could Ayesha and Benji's unshared intention that they <J$_1$, J$_2$> be a  shared intention?
This question might initially appear frivolous but it is not straightforward to answer.
Since Bratman provides only sufficient conditions for shared intention, his account doesn't tell us that the unshared intention is not a shared intention.
And while we might be tempted to assume that for two agents to intentionally J together they must at least each have intentions concerning J, 
this assumption might reasonably be rejected by those who, like Bratman, reject the Simple View according to which when an individual intentionally J-s she has an intention concerning her J-ing \citep{Bratman:1984jr}.

In defence of the second premise, (ii), consider that shared intentions are suppose to play a certain functional role.
Among other things, they are supposed to coordinate 







\section{Prior counterexamples}
***Must mention that Tollefsen and Gold \& Sugden counterexamples fail.


\section{The Counterexample}
Suppose that Aravinda runs the trains and Gerhard  the busses.
Let us stipulate that the extent to which the two services, train and bus, are coordinated is to be measured by the total time passengers spend waiting between a bus and a train.
So changes to the timetables would result in better coordination just if the changes would total waiting time.
To illustrate, improving coordination might involve having trains arrive at a station shortly before, rather than shortly after, busses depart from there.
Now Aravinda and Gerhard each intend that they, Aravinda and Gerhard, coordinate the trains with the busses to the greatest extent possible given other constraints; and they intend to do this by way of these intentions and meshing subplans of them, and this is common knowledge between them. 
Aravinda and Gerhard thus meet Bratman's sufficient conditions for them to have a shared intention.
Acting on this intention, 
every January Aravinda updates the train timetables and sends Gerhard the changes.
Likewise, Gerhard  updates the bus timetables every June and sends Aravinda the changes.
In this way  each is responsive to the other's intentions and subplans of these. 
Indeed, each may even try to predict changes in the other's subplans and modify their own accordingly.  
But from each individual's point of view, the other's plans are  merely a constraint.

***

So whether Gerhard succeeds relative to his intention depends on both his own and Aravinda's plans; and likewise for Aravinda.
%This is why each intends that they optimally coordinate the services in accordance with meshing subplans.
This is why each is responsive to the other's plans. 
Indeed, each may even try to predict changes in the other's plans and modify their own accordingly.  
But from each individual's point of view, the other's plans are  merely a constraint.
This approach to planning suffers from two defects.
First, it is unlikely to be optimal in the sense of resulting, eventually, in a combination of plans such that no other combination of plans would have been better for at least one service and no worse for either service.
Second, it is unlikely to be efficient in the sense of allowing Gerhard and Aravinda to arrive at an optimal combination of plans for the two services, trains and buses, with the fewest iterations.
How could they do better?
One possibility may be to have a single plan covering busses and trains---perhaps, for example, Aravinda could buy Gerhard's franchise. 
%But suppose that this is not possible, and that there are limits on how much information Aravinda and Gerhard can share. 
Now there is a single goal to which Aravinda and Gerhard's activities are both directed.
But suppose that this is not possible, and that they are unable to integrate their planning more tightly---practical constraints or regulation prevents them from opening up their planning to each other.
Can they still do better than treat each other's plans as a constraint?
Possibly.
Each plans the whole bus--train operation. 

New contrast case: Aravinda and Gerhard planning the whole thing vs. merely responding to each other's plans.
Meet Bratman's sufficient conditions for shared intention in both cases.
(Specifically, in both cases they act on a shared intention that they coordinate the trains with the busses to the greatest extent possible given other constraints.)
But intuitively is a case of coordinating the trains with the busses together whereas the other case involves Aravinda and Gerhard merely doing this in parallel.
So shared intention is insufficient to fully explain the contrast cases.

I'm also inclined to think it is not necessary for solving the contrast cases (distributive goals ...\ collective goals).
The contrast cases do not provide a firm anchor for theorising about shared intention.



\bibliography{$HOME/endnote/phd_biblio}



\end{document}